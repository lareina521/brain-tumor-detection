# -*- coding: utf-8 -*-
"""
Created on Sun Nov 13 21:53:12 2022

@author: Administrator
"""

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import os 
import glob
import cv2
import imutils
from sklearn.utils import shuffle
from skimage.io import imshow



def crop_brain_contour(image):
    
    # blur it slightly
    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(image, (5, 5), 0)

    # Threshold the image, then perform a series of erosions +
    # dilations to remove any small regions of noise
    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]
    thresh = cv2.erode(thresh, None, iterations=2)
    thresh = cv2.dilate(thresh, None, iterations=2)

    # Find contours in thresholded image, then grab the largest one
    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv2.contourArea)
    
    # Find the extreme points
    extLeft = tuple(c[c[:, :, 0].argmin()][0])
    extRight = tuple(c[c[:, :, 0].argmax()][0])
    extTop = tuple(c[c[:, :, 1].argmin()][0])
    extBot = tuple(c[c[:, :, 1].argmax()][0])
    
    # crop new image out of the original image using the four extreme points (left, right, top, bottom)
    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]] 
    
    return new_image

TRINING_DIR = "data/train/"
TEST_DIR = "data/test/"
image_size = 128
def readDataSet(dirr):
    data = []
    yes_path = os.path.join(dirr, "yes")
    for file in os.listdir(yes_path):
        image = cv2.imread(os.path.join(yes_path, file),cv2.IMREAD_GRAYSCALE)
        image = crop_brain_contour(image)
        image = cv2.resize(image,(image_size,image_size))
        data.append((image,1))
        
    no_path = os.path.join(dirr, "no")
    for file in os.listdir(no_path):
        image = cv2.imread(os.path.join(no_path, file),cv2.IMREAD_GRAYSCALE)
        image = crop_brain_contour(image)
        image = cv2.resize(image,(image_size,image_size))
        data.append((image,0))
      
    return data 
          
train_dataset  = shuffle(readDataSet(TRINING_DIR))  #takes a sequence, like a list, and reorganize the order of the items.
test_dataset = shuffle(readDataSet(TEST_DIR))
print("training dataset lenght : ",len(train_dataset) )
print("test dataset lenght : ",len(test_dataset) )
print("Images shape : ",train_dataset[1][0].shape)


def loop_func(img_p):
    img_path = img_p
    image = cv2.imread(img_path)
    
    dim=(500,590)
    
    
    image=cv2.resize(image, dim)
    #imshow( image)
    
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0.7)
    #imshow(gray)
    (T, thresh) = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY)
    #imshow(thresh)
    (T, threshInv) = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY_INV)
    
    
    #imshow(threshInv)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 5))
    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    #imshow(closed)
    closed = cv2.erode(closed, None, iterations = 14)
    closed = cv2.dilate(closed, None, iterations = 13)
    #imshow(closed)
    
    ret,mask = cv2.threshold(closed, 155, 255, cv2.THRESH_BINARY) 
    #apply AND operation on image and mask generated by thrresholding
    final = cv2.bitwise_and(image,image,mask = mask) 
    #plot the result
    #imshow(final)
    
    def auto_canny(image, sigma=0.33):
      # compute the median of the single channel pixel intensities
      v = np.median(image)
      # apply automatic Canny edge detection using the computed median
      lower = int(max(0, (1.0 - sigma) * v))
      upper = int(min(255, (1.0 + sigma) * v))
      edged = cv2.Canny(image, lower, upper)
      # return the edged image
      return edged
    canny = auto_canny(closed)
    #imshow(canny)
    (cnts, _) = cv2.findContours(canny.copy(), cv2.RETR_EXTERNAL,
    cv2.CHAIN_APPROX_SIMPLE)
    cv2.drawContours(image, cnts, -1, (0, 0, 255), 2)
    imshow(image) 
    return image

for name in glob.glob('data/train/yes/*'): 
  name = name.replace('\\','/')
  #print(name)
  loop_func(name)



from skimage.feature.texture import graycomatrix , graycoprops
def  textureFeatures(image):                            # find the roi
    GLCM = graycomatrix(image, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])
    energy = graycoprops(GLCM, 'energy')[0, 0]
    corr = graycoprops(GLCM, 'correlation')[0, 0]
    homogen = graycoprops(GLCM, 'homogeneity')[0, 0]
    contrast = graycoprops(GLCM, 'contrast')[0, 0]
    
    features_texture = np.array([contrast,energy,homogen,corr])
    features_texture /= np.sum(features_texture,axis=0);
    return features_texture.reshape(-1)  #reshape(-1) refers to an unknown dimension that the reshape() function calculates for you.

#claculating the hog 
from skimage.feature import hog
from mahotas.features import haralick
import cv2 as cv

# like canny edge detection,used for object detection
def hog_feature(image):
    fd, hog_feature = hog(image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)
    return hog_feature.reshape(-1)
#Histogram of Oriented Gradients 
#the complete image is broken down into smaller regions and for each region, the gradients and orientation are calculated

# bins for histogram
bins = 8

def fd_hu_moments(image):       #Hu Moments that quantifies shape The argument to this function is the moments of the image cv2.moments() flatenned. It means we compute the moments of the image and convert it to a vector using flatten(). Before doing that, we convert our color image into a grayscale image as moments expect images to be grayscale.
    feature = cv.HuMoments(cv.moments(image)).flatten()
    feature /= np.mean(feature)
    return feature.reshape(-1)

# Haralick Texture  that quantifies texture
def fd_haralick(image):
    haralickF = haralick(image).mean(axis=0)
    return haralickF.reshape(-1)

from mahotas.features import surf   #speeded up robust features
def surf_feature(image):# detect and describe local features in images.
    fi = surf.integral(image.copy())   #getting Speeded-Up Robust integral feature
    points = surf.interest_points(fi, 6, 24, 1, max_points=1024, is_integral=True)  #take any number of reference images.
    
    descs = surf.descriptors(fi, points, is_integral=True, descriptor_only=True)
    return descs.reshape(-1)

def extractAllFeatures(dataset):
    X = []
    Y = []
    for i in range(len(dataset)):
        fv_haralick  = fd_haralick(dataset[i][0])
        fv_hu_moments = fd_hu_moments(dataset[i][0])
        fv_texture = textureFeatures(dataset[i][0])
        fv_hog = hog_feature(dataset[i][0])
        fv_surf = surf_feature(dataset[i][0])
        
        global_feature = np.hstack([fv_hu_moments,fv_haralick,fv_texture,fv_hog,fv_surf])
        #stack the sequence of input arrays horizontally  to make a single array.
        X.append(global_feature)
        Y.append(dataset[i][1])
    return np.array(X),np.array(Y).reshape(-1)   
  
X_train , Y_train = extractAllFeatures(train_dataset)
X_test , Y_test = extractAllFeatures(test_dataset)


scaler = StandardScaler() #create an instance of standard scaler  ensure the data has zero mean and unit variance
scaler.fit(X_train) # fit it to the training data

X_train = scaler.transform(X_train) #transform training data
X_test = scaler.transform(X_test)
     
class SVM:
    def __init__(self, iterations=1000, lr=0.01, lambdaa=0.01):
        self.lambdaa = lambdaa
        self.iterations = iterations
        self.lr = lr
        self.w = None
        self.b = None
        

    def initialize_parameters(self,X):
        #get number of examples and number of features
        m, n = X.shape
        #initialize w to array of zeros of the shape of number of features
        # Note intializing w to random array will sometimes yield better/worse results
        self.w = np.zeros(n)
        #intialize b to zero
        self.b = 0

        
    def gradient_descent(self, X, y):
        # set y to -1 if it's equal or less than 0, else set it to 1
        y_ = np.where(y <= 0, -1, 1)
        # loop over the indexes and elements in X
        for i, x in enumerate(X):
            #Check if the condition mentioned above is true and set dw, db accordingly
            if y_[i] * (np.dot(x, self.w) - self.b) >= 1:
                dw = 2 * self.lambdaa * self.w
                db = 0
            else:
                dw = 2 * self.lambdaa * self.w - np.dot(x, y_[i])
                db = y_[i]
                #update the weights using update weight function
            self.update_parameters(dw,db)

        
    def update_parameters(self, dw, db):
        
        self.w = self.w - self.lr * dw
        self.b = self.b - self.lr * db

        
    def fit(self, X, y):
        #intialize parameters
        self.initialize_parameters(X)
        #loop for specified number of iterations
        for i in range(self.iterations):
            #get the gradients and update weights
            self.gradient_descent(X,y)
            
            
    def predict(self, X):
        # get the outputs
        output = np.dot(X, self.w) - self.b
        # get the signs of the labels depending on if it's greater/less than zero
        label_signs = np.sign(output)
        #set predictions to 0 if they are less than or equal to -1 else set them to 1
        predictions = np.where(label_signs <= -1, 0, 1)
        return predictions


from sklearn.metrics import classification_report, confusion_matrix
model = SVM()
model.fit(X_train,Y_train)
predictions = model.predict(X_test)
print(confusion_matrix(Y_test, predictions))
print(classification_report(Y_test, predictions))
print("SVM accuracy : ",accuracy_score(Y_test,predictions))
